{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1685643928753,"user":{"displayName":"Hichem FARAOUN","userId":"15193157925684900568"},"user_tz":-60},"id":"34nq7iTlIUN8"},"outputs":[],"source":["# Create folder to make inside them the videos\n","!mkdir REFERENCE_VIDEOS\n","!mkdir DISTORTED_VIDEOS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0s3eiw4g3fq0"},"outputs":[],"source":["# LPIPS For the objective score calculation\n","!pip install lpips"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685643934145,"user":{"displayName":"Hichem FARAOUN","userId":"15193157925684900568"},"user_tz":-60},"id":"16Q1cARz3kTi"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import cv2\n","import pandas as pd\n","import torch\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import subprocess\n","from tqdm import tqdm\n","from lpips import lpips\n","\n","# AlexNet => Best Forward, see the documentation\n","loss_fn = lpips.LPIPS(net='alex')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RL7BwED0qA8D"},"outputs":[],"source":["def read_frame_extract_patches(ref_frame, dis_frame):\n","\n","  # /ref will contain the refernces frames (it will be consistent for all the distorted videos of the refernce video)\n","  # read refernce frame\n","  ref_image = Image.open('ref/' + ref_frame)\n","  \n","  # read distorted frame\n","  dis_image = Image.open(dis_frame).convert('RGB')\n","  \n","  # if the frame shape is not [1920*1080] then resize it using BUCIBIC Filter\n","  height = dis_frame.split('_')[4].split('x')[1]\n","  if (height != 1080):\n","    dis_image = dis_image.resize((1920, 1080), resample=Image.BICUBIC)\n","  \n","  # convert to numpy array\n","  dis_img = np.array(dis_image)\n","  ref_img = np.array(ref_image)\n","\n","  # convert from 1920*1090*3 to 1*1920*1080*3\n","  ref_img = tf.expand_dims(ref_img, axis=0)\n","  dis_img = tf.expand_dims(dis_img, axis=0)\n","\n","  #cast type to float32\n","  ref_img = tf.cast(ref_img, dtype=tf.float32)\n","  dis_img = tf.cast(dis_img, dtype=tf.float32)\n","  \n","\n","  # Extract the patches from the images\n","  patch_size = (299, 299, 3)\n","  # no overlapping patches\n","  strides = (1, 299, 299, 1)\n","  dis_patches = tf.image.extract_patches(dis_img, sizes=[1, 299, 299, 1], strides=strides, rates=[1, 1, 1, 1], padding='VALID')\n","  ref_patches = tf.image.extract_patches(ref_img, sizes=[1, 299, 299, 1], strides=strides, rates=[1, 1, 1, 1], padding='VALID')\n","\n","  # Reshape the patches to 18x299x299x3\n","  dis_patches = tf.reshape(dis_patches, [-1, *patch_size])\n","  ref_patches = tf.reshape(ref_patches, [-1, *patch_size])\n","\n","  return ref_patches, dis_patches # need to be divided by 255."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bruNPo2DqEnv"},"outputs":[],"source":["def calculate_lpips(references, distorted):\n","  \n","  # refernces patches\n","  references = references.numpy()/255.\n","  # distorted patches\n","  distorted = distorted.numpy()/255.\n","\n","  #normalize to [-1 1], see documentation\n","  references = references  * 2.0 - 1.0\n","  distorted = distorted  * 2.0 - 1.0\n","\n","  #convert tp pytroch tensor\n","  references = torch.tensor(references.transpose(0, 3, 1, 2))\n","  distorted = torch.tensor(distorted.transpose(0, 3, 1, 2))\n","\n","  #lpips forward\n","  distance = loss_fn.forward(references, distorted)\n","\n","  return distance[:, 0, 0, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDZAmtLoJKkv"},"outputs":[],"source":["# Read the videos files names\n","# References\n","ref_videos = os.listdir('REFERNCES_VIDEOS')\n","\n","# Disrtorted by subset dataframe or by folder\n","dis_videos = pd.read_csv('selected_ditorted.csv')['Video'].values\n","# dis_videos = os.listdir('DISTIRTED_VIDEOS')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTd6BTDyoJPR"},"outputs":[],"source":["# 'number' is only to say 'Patches_1' or 'Patches_2'...\n","def one_frame_processing(reference_frame, distorted_frame, number):\n","\n","\n","  output_patches_folder = f'Patches_{number}/'\n","\n","  ref_patches, dis_patches = read_frame_extract_patches(reference_frame, distorted_frame)\n","  \n","  patches_lpips_scores = calculate_lpips(ref_patches, dis_patches)\n","\n","  # '/255', to save them\n","  dis_patches = dis_patches / 255.\n","\n","  patches_names = []\n","  for j, (patch) in enumerate(dis_patches):\n","\n","    # To delete the '.png' extension\n","    distorted_frame_name = distorted_frame.split('.')[0]\n","\n","    patch_name = distorted_frame_name + f'_patch_{j+1}.png'\n","    patch_path = output_patches_folder + patch_name\n","    plt.imsave(patch_path, patch.numpy(), format='png')\n","\n","    patches_names.append(patch_name)\n","\n","  return patches_names, patches_lpips_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeQhPjM1PGGc"},"outputs":[],"source":["def Videos_process(reference_videos, distorted_videos, number):\n","  \n","\n","  \n","  patches_csv = f'patches_{number}.csv'\n","  ref_path = 'REFERENCE_VIDEOS'\n","  dis_path = 'DISTORTED_VIDEOS'\n","  \n","  tqdm_bar = tqdm(reference_videos)\n","  header_patch = ['Patch', 'Lpips Score']\n","\n","  with open(patches_csv, 'a') as w:\n","    w.write(','.join(header_patch) + '\\n')\n","    for ref_video in tqdm_bar:\n","      ref_video_name_content = ref_video.split('_')\n","\n","      # Each video is for a specific game name\n","      game_name = ref_video_name_content[0]\n","      # In one dataset, there is two part fro each game, if there is only one part this line can be deleted\n","      game_part = ref_video_name_content[3].split('.')[0]\n","\n","      # To get all the distirted videos belong to the refernce video\n","      distorted = []\n","      for dis_video in distorted_videos:\n","        \n","        if (dis_video.split('_')[0] == game_name and dis_video.split('_')[3] == game_part):\n","          distorted.append(dis_video)\n","        \n","        # In the case of a video game has one part only\n","        # if (dis_video.split('_')[0] == game_name):\n","        #   distorted.append(dis_video)\n","          \n","      # ref is true means a new reference video with new disrtorted videos.  \n","      ref = True\n","\n","      # the ref folder will contain all the refernce video frames for all the disrtoed videos\n","      os.system('mkdir ref')\n","      for i, dis_video in enumerate(distorted):\n","        cap = cv2.VideoCapture(os.path.join(dis_path, dis_video))\n","        video_frames = 900 # 30 second * 30 frame per second\n","        \n","        # the step is 12 , so take every 13th frame\n","        for frame in range(0, video_frames, 12):\n","\n","          \n","          if(ref):\n","            # extract refernce frame and save it\n","            ref_frame = ref_video.split('.')[0] + f'_{frame}.png'\n","            extract_ref_png_frame = ['ffmpeg', '-y', '-s', f'{1920}x{1080}', '-pix_fmt', 'yuv420p', '-i', os.path.join(ref_path, ref_video), '-vf', f'select=eq(n\\,{frame})', '-vframes', '1', ref_frame]\n","            subprocess.call(extract_ref_png_frame)\n","            os.system(f'mv {ref_frame} /content/ref/{ref_frame}')\n","              \n","          # for the distorted frame name \n","          dis_frame = dis_video.split('.')[0] + f'_{frame}.png'        \n","\n","          \n","          # save the disrtoted frame\n","          cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n","          ret, img = cap.read()\n","          plt.imsave(dis_frame, img) \n","          dis_image = Image.open(dis_frame)\n","          height = dis_frame.split('_')[4].split('x')[1]\n","          if (height != 1080):\n","            dis_image = dis_image.resize((1920, 1080), resample=Image.BICUBIC)\n","            \n","          patches_names, lpips_scores = one_frame_processing(ref_video.split('.')[0] + f'_{frame}.png', dis_frame, number)\n","\n","          # save the patches name with their scores to the csv file\n","          for (patch, score) in zip(patches_names, lpips_scores):\n","            data = ','.join([patch, str(score.item())]) + '\\n'\n","            w.write(data)\n","\n","          # delete the processed distorted frame\n","          os.system(f'rm {dis_frame}')\n","\n","          # update the result to the plot bar\n","          tqdm_bar.set_postfix({'distorted_video_processed': f'{i}/{len(distorted)}', 'frame processed': frame})\n","        # setting ref = false , will stop the processing of the ref video as it is ready for the next distorted video\n","        ref = False\n","        \n","        # close the video\n","        cap.release()\n","      # delete the ref video\n","      os.system('rm -r ref')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2425290,"status":"ok","timestamp":1685456697933,"user":{"displayName":"Hichem FARAOUN","userId":"15193157925684900568"},"user_tz":-60},"id":"XUKGYuF1Qvr4","outputId":"7f153e47-de29-4448-a27d-d580db525d3e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [40:24<00:00, 606.22s/it, dis=2/3, frame=888]\n"]}],"source":["number = 1\n","os.system(f'mkdir Patches_{1}')\n","Videos_process(ref_videos, dis_videos, number)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WNxpnGKRAhd"},"outputs":[],"source":["# Zip the result folder\n","os.system(f'zip -r Patches_{number}.zip Patches_{number}')"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
